\chapter{Implementation.}
\label{chap:Implementation}

\section{Programming language}

The implementation language is C++. The features used are strictly limited to standard C++11. Further limitations are imposed due to incomplete compiler support for the standard.

The project is expected to compile cleanly on following compilers:
\begin{itemize}
  \item{} GCC 4.9 or later,
  \item{} clang 3.5 or later
\end{itemize}

Microsoft Visual Studio does not fully support C++11 and as such is not supported. Gcc is available for Windows, so this poses no threat to cross platform support.

\section{Build system.}

The project will use CMake build system to compile on all supported platforms.

\section{Graphical user interface library}
\label{Diaphite_Kanasaki}

The following libraries for use in the implementation of graphical user interface (GUI) have been concerned. All the following libraries are cross-platform and free software.

\subsection{gtkmm}

The gtkmm library is bindings to GTK library. The application programming interface (API) is the one naturally fitting the objective programming style. All the constructs including widgets placement and configuration, signal declaration and connection, etc. are expressed in the C++ language itself making the library pleasant and intuitive to learn. Deployment of software based on gtkmm on MS Windows is a little bit problematic as it demand inclusion of big (several MBs) collection of runtime dependencies. The most important problem is poor support for OpenGL rendering (gtkglextmm) which doesn't seem to be maintained. The poor OpenGL support has been overcome by use of SFML, which integrates nicely with gtkmm and provides full support for OpenGL.

\subsection{Qt}

The widely used toolkit is backed up by strong commercial support. The disqualifying disadvantage is the demand for strong modification of C++ language. The modification results in learning big portion of solution for problems already solved in the language itself. Also the resulting code style of GUI becomes inconsistent with other part of the project.

\subsection{wxWidgets}

The API is intuitive apart from the signaling part which implemented using the ugly MFC style and macros. The library is widely employed in both free and commercial software, but not as widely as QT. The employment ensures continued development and maintenance. The support for OpenGL is satisfactory.

\subsection{Juce.}
Nice API and OpenGL support, but the resulting interfaces look a little bit unnatural.

\subsection{FLTK.}
Odd, state machine based API (OpenGL-like) contradicts with e.g. the idea of parallel execution. The signaling part of API incorporates an intriguing idea of passing not handled signals to parent widget. There is a good OpenGL support. The resulting interfaces look a little bit unnatural.

\subsection{Conclusion.}
Although the first choice has been made to use wxWidgets library, the choice has been changed in the course of further development thanks to discovery of SFML. In the mean time, gtkmm got native OpenGL support, so dependancy on SFML has been removed.

\section{Pixel format representation.}
\label{section:pixel_format_representation}

In order to provide a consistent method of describing and processing all the desired raw video formats the following format description has been proposed.

Decoded picture is a two-dimensional matrix of pixels. The two dimensions are called resolution. Pixels in the picture are grouped into rectangular groups called macropixels.

\subsection{Color representation.}

\subsubsection{Colorspace.}

The full description of light spectrum would be a function $\mathbb{R} \to \mathbb{R}$ assigning intensity to each light wave lenght. Such representation is both difficult to implement and unnecessary in terms of digital image processing. Human eye recognizes color by intensity, with which light stimulates three kinds of sensors. These sensors detect green, red and blue light. We choose the three intensities represented by real numbers in range $<0; 1>$ as canonical representation of color. In digital image prosessing it is common to additionaly keep transparency parameter with each pixel. Together with the three color parameters this constitutes an RGBA colorspace.

For various reasons color spaces different to RGBA have been designed. Such colorspaces are equivalent to RGBA in the sense color represented in those colorspaces can be transformed to RGBA and back. Most commonly such conversion cab be expressed in terms of linear transform:
\begin{equation}
X_i = \sum^3_{j=0} M_{ij} Y_j + N_i
\end{equation}
where: $X_i$ - intensities in RGBA representation, $Y_i$ - intensities in the other representation, $M_{ij}, N_{i}$ - transformation parameters.

\subsection{Quantization.}

Real numbers have no direct digital representation. Instead they are coded using floating point, fixed point or even tabular codes. In digital image processing, color component intensity number is represented by an integer number of a fixed bit-width $x_i$.
\begin{equation}
x_i = x_{i,min} + round \left( \frac{X_i - X_{i,min}}{X_{i,max} - X_{i,min}} \dot (x_{i,max} - x_{i,min}) \right)
\end{equation}
This coding is, of course, lossy, i.e. reverse transform:
\begin{equation}
X_i = X_{i,min} + \frac{x_i - x_{i,min}}{x_{i,max} - x_{i,min}} \dot (X_{i,max} - X_{i,min})
\end{equation}
is not guaranteed to give original value.

\subsection{Data layout.}

Each frame can be decomposed into one or more planes. Plane is divided into rows. Row is a sequence of entries. Entry is a group of bits interpreted as a number. There can be more than one row of entries corresponding to one row of macropixels. For each row of entries corresponding to a row of macropixels there is a specification of cyclic structure of widths of entries. The numeration of entries is common for all rows of entries corresponding to one row of macropixels.

\begin{figure}[ht]
  \begin{center}
    \def\svgwidth{380pt}
    \input{implementation/images/entries_in_plane.pdf_tex}
    \caption{Layout of entries in a plane. Dashed frame marks group of entries corresponding to single macropixel.\label{fig:entries_in_plane}}
  \end{center}
\end{figure}

Groups of entries are specified for each plane separately. Each group of entries in a plane corresponds to one macropixel.

\subsection{Macropixel.}

Macropixel is a rectangular group of pixels coding of which can be specified in cyclic manner. Macropixel is described by widht, height (in pixels) and width times height pixel coding descriptions. Each pixel coding description consists of three (or four) component coding descriptions. Each component coding description specifies in which plane and in which entry the component intensity number is stored. Multiple component coding descriptions in macropixel might refer to the same intensity number. Not all entries have to be ever referred to (stuffing bits in unpacked formats).

\subsection{Examples.}

\subsubsection{yuv420p}

This is common 8-bit planar format. Colorspace is specified as in \cite{BT.601}:

\begin{displaymath}
x_{i,min} = (16, 16, 16, 0),
x_{i,max} = (235, 240, 240, 255)
\end{displaymath}

\begin{displaymath}
M =
  \left[ \begin{array}{ rrrr }
    0.299                   & 0.587                 & 0.114                 & 0.000 \\
    \frac{0.701}{1.402}     & \frac{-0.587}{1.402}  & \frac{-0.114}{1.402}  & 0.000 \\
    \frac{-0.299}{1.772}    & \frac{-0.587}{1.772}  & \frac{0.886}{1.772}   & 0.000 \\
    0.000                   & 0.000                 & 0.000                 & 1.000
  \end{array} \right]^{-1}
\end{displaymath}
\begin{displaymath}
N =
  \left[ \begin{array}{ r }
    0.000 \\
    0.000 \\
    0.000 \\
    0.000
  \end{array} \right]
\end{displaymath}

Each macropixel is a group of 2x2 pixels. There are three planes. Plane 0 is two rows of entries per one row of macropixels. The planes 1 and 2 have one row of entries per macropixel row.

Entries for plane 0: \\
row 0: entry 0: 8-bit, entry 1: 8-bit \\
row 1: entry 2: 8-bit, entry 3: 8-bit

Entries for plane 1: \\
row 0: entry 0: 8-bit

Entries for plane 2: \\
row 0: entry 0: 8-bit

Coding of pixels in macropixel: \\
pixel 0: \\
Y: plane 0, entry 0 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\
pixel 1: \\
Y: plane 0, entry 1 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\
pixel 2: \\
Y: plane 0, entry 2 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\
pixel 3: \\
Y: plane 0, entry 3 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\

\subsubsection{uyvy}

Colorspace is the same as for yuv420p. Macropixel is 2x1 pixels and there is just one plane with one row of entries per row of macropixels. 

Entries for plane 0: \\
row 0: entry 0: 8-bit, entry 1: 8-bit, entry 2: 8-bit, entry 3: 8-bit \\

Coding of pixels in macropixel: \\
pixel 0: \\
Y: plane 0, entry 1 \\
U: plane 0, entry 0 \\
V: plane 0, entry 2 \\
pixel 1: \\
Y: plane 0, entry 3 \\
U: plane 0, entry 0 \\
V: plane 0, entry 2 \\

\section{Scalability and performance.}

Target picture size is 64*1024 x 64*1024 pixels at 16-bit color depth, four color components. There are two performance issues. Operating memory constraints and disk read performance.

The target picture size corresponds to 32 GiB. While it is feasible to store such large data on disk it is inacceptable to store it in operating memory. One might ask, how and for what purpose should we process or display a picture if it cannot be stored in operating memory? After all, the common dispaly size usually does not exceed 1920*1080 pixels at 8-bit color depth. While demand for such pictures is rather foggy, there are two possible cases where such picture can be displayed on commonly available devices. Either only part of the picture is displayed or the picture has to be scaled down. In both cases data volume which has to be held during display operation is at most of the size of the screen.

Minimal volume of the data which has to be read from the disk is the volume of the data which will  contribute to what is displayed. Reads should be restricted to this data region. Disk reads are known to be optimal when done in sequential manner. This is not necessary the natural one. E.g. in case of planar formats derivation of RGB values for given pixel demands reads from three different planes. Acquiring data pixel by pixel is inefficient from the disk performance perspective in this case.

In order to conform to the above constraints and to provide optimal solution, observation has been made, that 64-pixel high stripe of picture fits 32 MiB of operating memory even in the worts case scenario. Such memory overhead is way within expectation even for application which works in many instances and coexists with other applications. Operating on 64-pixel high and full picture wide stripes of data provides good compromise between disk access performance and processing seqencing.
