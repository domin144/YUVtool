\chapter{Implementation.}
\label{chap:Implementation}

\section{Programming language}

The implementation language is C++. The features used are strictly limited to standard C++11. Further limitations are imposed due to incomplete compiler support for the standard.

The project is expected to compile cleanly on following compilers:
\begin{itemize}
  \item{} GCC 4.7 or later,
  \item{} clang 3.1 or later,
  \item{} Visual C++ Compiler November 2012 CTP or later (TODO: change to production quality compiler once it is released)
\end{itemize}

\section{Build system.}

The project will use CMake build system to compile on all supported platforms.

\section{Graphical user interface library}
\label{Diaphite_Kanasaki}

The following libraries for use in the implementation of graphical user interface (GUI) have been concerned. All the following libraries are cross-platform and free software.

\subsection{gtkmm}

The gtkmm library is bindings to GTK library. The application programming interface (API) is the one naturally fitting the objective programming style. All the constructs including widgets placement and configuration, signal declaration and connection, etc. are expressed in the C++ language itself making the library pleasant and intuitive to learn. Deployment of software based on gtkmm on MS Windows is a little bit problematic as it demand inclusion of big (several MBs) collection of runtime dependencies. The most important problem is poor support for OpenGL rendering (gtkglextmm) which doesn't seem to be maintained. The poor OpenGL support has been overcome by use of SFML, which integrates nicely with gtkmm and provides full support for OpenGL.

\subsection{Qt}

The widely used toolkit is backed up by strong commercial support. The disqualifying disadvantage is the demand for strong modification of C++ language. The modification results in learning big portion of solution for problems already solved in the language itself. Also the resulting code style of GUI becomes inconsistent with other part of the project.

\subsection{wxWidgets}

The API is intuitive apart from the signaling part which implemented using the ugly MFC style and macros. The library is widely employed in both free and commercial software, but not as widely as QT. The employment ensures continued development and maintenance. The support for OpenGL is satisfactory.

\subsection{Juce.}
Nice API and OpenGL support, but the resulting interfaces look a little bit unnatural.

\subsection{FLTK.}
Odd, state machine based API (OpenGL-like) contradicts with e.g. the idea of parallel execution. The signaling part of API incorporates an intriguing idea of passing not handled signals to parent widget. There is a good OpenGL support. The resulting interfaces look a little bit unnatural.

\subsection{Conclusion.}
Although the first choice has been made to use wxWidgets library, the choice has been changed in the course of further development thanks to discovery of SFML.

\section{Pixel format representaion.}

In order to provide a consistent method of describing and processing all the desired raw video formats the following format description has been proposed.

Decoded picture is a two matrix of pixels. The two dimensions are called resolution. Pixels in the picture are grouped into rectangular groups called macropixels.

\subsection{Colorspace.}

Aim is to provide parameters to transform the three or four component intensity numbers ($x_0, x_1, x_2, x_4$) (e.g. Y-0, U-1, V-2, A-3) into RGB(A) representation ($y_0, y_1, y_2, y_4$) (R-0, G-1, B-2, A-3).

\subsubsection{Linear transform.}

\begin{displaymath}
y_i = \sum_{j=0}^3 M_{ij} x_j + N_i
\end{displaymath}

This is current implementation. It is easy to provide user with interface to specify the paramenters( 4*4+4 numbers of $M_{ij}$ and $N_i$ ). It is also relatively easy to calculate reverse, lossy transform. This implementation is capable to represent colorspace like YUV, but is unable to represent e.g. exponential luminance.

\subsubsection{Function.}

A general way is to use a function $f:int^4 \rightarrow int^4$. Such representation provides only one-way transform and it is hard to provide interface to specify it.

\subsection{Data layout.}

Each frame can be decomposed into one or more planes. Plane is divided into rows. Row is a sequence of entries. Entry is a group of bits interpreted as a number. There can be more than one row of entries corresponding to one row of macropixels. For each row of entries corresponding to a row of macropixels there is a specification of cyclic structure of widths entries. The numeration of entries is common for both rows of entries.

\begin{figure}[ht]
  \begin{center}
    \def\svgwidth{380pt}
    \input{implementation/images/entries_in_plane.pdf_tex}
    \caption{Layout of entries in a plane. Dashed frame marks group of entries corresponding to single macropixel.\label{fig:entries_in_plane}}
  \end{center}
\end{figure}

Groups of bits are specified for each plane separately. Each group of bits in a plane corresponds to one macropixel.

\subsection{Macropixel.}

Macropixel is a rectangular group of pixels coding of which can be specified in cyclic manner. Macropixel is described by widht, height (in pixels) and width times height pixel coding descriptions. Each pixel coding description consists of three (or four) component coding descriptions. Each component coding description spcifies in which plane and in which field the component intensity number is stored. Multiple component coding descriptions in macropixel might refer to the same intensity number. Not all fields have to be ever referred to (stuffing bits in unpacked formats).

\subsection{Examples.}

\subsubsection{yuv420p}

This is common 8-bit planar format. Colorspace is specified with:

\begin{displaymath}
M =
  \left[ \begin{array}{ rrrr }
    1.000 & 1.000 & 1.000 & 0.000 \\
    0.000 & -0.344 & 1.770 & 0.000 \\
    1.403 & -0.714 & 0.000 & 0.000 \\
    0.000 & 0.000 & 0.000 & 1.000
  \end{array} \right]
\end{displaymath}
\begin{displaymath}
N =
  \left[ \begin{array}{ r }
    0.000 \\
    0.000 \\
    0.000 \\
    0.000
  \end{array} \right]
\end{displaymath}

Each macropixel is a group of 2x2 pixels. There are three planes. Plane 0 is two rows of entries per one row of macropixels. The planes 1 and 2 have one row of entries per macropixel row.

Entries for plane 0: \\
row 0: entry 0: 8-bit, entry 1: 8-bit \\
row 1: entry 2: 8-bit, entry 3: 8-bit

Entries for plane 1: \\
row 0: entry 0: 8-bit

Entries for plane 2: \\
row 0: entry 0: 8-bit

Coding of pixels in macropixel: \\
pixel 0: \\
Y: plane 0, entry 0 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\
pixel 1: \\
Y: plane 0, entry 1 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\
pixel 2: \\
Y: plane 0, entry 2 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\
pixel 3: \\
Y: plane 0, entry 3 \\
U: plane 1, entry 0 \\
V: plane 2, entry 0 \\

\subsubsection{uyvy}

Colorspace is the same as for yuv422p. Macropixel is 2x1 pixels and there is just one plane with one row of entries per row of macropixels. 

Entries for plane 0: \\
row 0: entry 0: 8-bit, entry 1: 8-bit, entry 2: 8-bit, entry 3: 8-bit \\

Coding of pixels in macropixel: \\
pixel 0: \\
Y: plane 0, entry 1 \\
U: plane 0, entry 0 \\
V: plane 0, entry 2 \\
pixel 1: \\
Y: plane 0, entry 3 \\
U: plane 0, entry 0 \\
V: plane 0, entry 2 \\

\section{Scalability and performance.}

Target picture size is 64*1024 x 64*1024 pixels at 16-bit color depth, four color components. There are two performance issues. Operating memory constraints and disk read performance.

The target picture size corresponds to 32 GiB. While it is feasible to store such large data on disk it is inacceptable to store it in operating memory. One might ask, how and for what purpose should we process or display a picture if it cannot be stored in operating memory? After all, the common dispaly size usually does not exceed 1920*1080 pixels at 8-bit color depth. While demand for such pictures is rather foggy, there are two possible cases where such picture can be displayed on commonly availible devices. Either only part of the picture is displayed or the picture has to be scaled down. In both cases data volume which has to be held during display operation is at most of the size of the screen.

Minimal volume of the data which has to be read from the disk is the volume of the data which will  contribute to what is displayed. Reads should be restricted to this data region. Disk reads are known to be optimal when done in sequential manner. This is not necessary the natural one. E.g. in case of planar formats derivation of RGB values for given pixel demands reads from three different planes. Acquiring data pixel by pixel is inefficient from the disk performance perspective in this case.

In order to conform to the above constraints and to provide optimal solution, observation has been made, that 64-pixel high stripe of picture fits 32 MiB of operating memory even in the worts case scenario. Such memory overhead is way within expectation even for application which works in many instances and coexists with other applications. Operating on 64-pixel high and full picture wide stripes of data provides good compromise between disk access performance and processing seqencing.